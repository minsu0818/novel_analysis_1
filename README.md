# novel_analysis_1
## 서론
### 1. 웹소설의 등장
과거 우리나라에는 『드래곤 라자』, 『눈물을 마시는 새』 같은 판타지 소설들이 서점에서 큰 인기를 끌었다. 이들 소설은 여타 문학작품처럼 작가의 철학을 깊이 고민하게 하거나 특별한 교훈을 주는 작품들은 아니었다. 하지만 독자들에게는 권선징악에서 오는 카타르시스와 현실을 잠시 잊게 만드는 흥미로운 이야기들이 큰 매력으로 다가왔다. 마치 소설계의 간식처럼, 부담 없이 가볍게 즐길 수 있다는 점이 판타지 장르 소설의 특징이었기에, 평소에 소설을 읽지 않던 사람들조차 쉽게 손을 뻗게 되었다. <br/><br/>

이 시기, 판타지 소설 시장은 점점 커지기 시작했지만 여전히 종이책 중심의 문화였고, 그때만 해도 조아라, 문피아와 같은 웹소설 플랫폼들은 존재했지만 지금과 같은 활기찬 모습은 아니었다. 하지만 2010년대 스마트폰의 급속한 보급은 판타지 소설뿐만 아니라 소설 시장 전체에 새로운 전환점을 가져왔다. 더 이상 종이책을 사서 읽어야 할 필요 없이, 스마트폰만 있으면 언제 어디서든 소설을 읽을 수 있는 웹소설이 등장하게 됐다.

### 2. 웹소설 시장의 성장 <br/>
![image](https://github.com/user-attachments/assets/bb115d6e-3943-4274-a2b7-c27eaf693088)<br/>

위 그래프가 보여주듯, 웹소설 시장은 2013년부터 2024년까지 폭발적인 성장을 기록했다.

2013년에는 불과 100억 원에 불과했던 시장이 2024년에는 1조 원을 훌쩍 넘어 1조 1000억 원 규모까지 성장했다.
이는 스마트폰의 대중화, 웹소설 플랫폼의 발전, 그리고 독자들의 소비 패턴 변화가 맞물려 시장이 빠르게 확대되었기 때문이다. 처음에는 종이책 시장을 대체하는 수준이었지만, 이제는 다양한 미디어로 확장되며 강력한 문화 콘텐츠로 자리 잡은 것이다

이렇게 단순한 '시간 죽이기'를 넘어선 웹소설의 성장은 더 이상 가볍게 볼 수 없는 하나의 산업 혁신으로 이어졌고, 그 성과를 이 그래프가 명확히 증명하고 있다.

### 3.댓글의 등장 <br/>

웹소설의 결제 방식이 과거와 달리 편당 결제 시스템으로 변화하면서 다양한 변화가 생겼다.
가장 눈에 띄는 변화는 바로 댓글 시스템이다.

과거에는 작가와 독자 간의 소통이 거의 불가능했지만, 현재는 매 편마다 댓글을 통해 독자들이 자신의 생각이나 느낀점을 자유롭게 작성할 수 있게 되었다.
또한, 댓글은 단순한 의견 개진을 넘어서 작품의 여론이나 재미 여부를 판단하는 중요한 기준이 되기도 한다.

결국, 편당 결제 시스템의 도입은 작품을 보다 유연하고 효율적으로 소비할 수 있는 환경을 만들었고, 댓글 시스템을 통해 작가와 독자 간의 소통을 활성화했다.

### 4. 문제 정의 

웹소설은 인터넷 서브컬쳐의 한 분야이기 때문에 평점 시스템이 존재한다. 평점이 높을수록 해당 작품의 여론이 긍정적이라는 의미로 해석되는데, 그렇다면 평점이 높은 작품들은 과연 부정적인 댓글의 비율이 적을까?

이를 분석하기 위해 나는 KoEleTra를 사용하여 평점과 작품에 대한 긍부정 댓글의 관계를 살펴보고자 한다. KoEleTra는 한국어 텍스트 감정 분석에 유용한 도구로, 댓글의 긍정적, 부정적 비율을 정량적으로 분석할 수 있다.

이 분석을 통해 평점이 단순히 독자들의 호감도에 비례하는지, 아니면 다른 요인이 개입하는지를 확인하고, 웹소설의 여론 구조를 보다 깊이 이해할 수 있을 것이다.

## 2. 데이터 들여다 보기

* 데이터 수집 기준 <br/>
댓글이 많은 소설들에서 1화부터 25화까지의 댓글을 수집하여 대략 30000만개의 데이터를 수집하고자 했습니다.<br/>

* 데이터  

|number|file_name|Comment|Date|
|------|---------|-------|----|
|1|검은 머리 미군 대원수 대체역사|"조범석 아르민 산신령 합작 레토나 ㅋㅋㅋ.심지어 약관 위배하고 조져버리다니 슬프다"|20240305|
|2|검은 머리 미군 대원수 대체역사|다시 왔습니다... 그립진 않습니다 대머리 듀오...|20240308|
|3|검은 머리 미군 대원수 대체역사|정주행 시작|20240312|
|.....|..........|.................|.........|
|27900|회귀수선전 무림|헉헉. 숨도 못쉬게 읽고 무아지경에 이르다니…|20230325|
|27901|회귀수선전 무림|존잼|20230326|
|27902|회귀수선전 무림|재밌어요|20230326|
|27903|회귀수선전 무림|서은현이 벤다|20230326|


총 9개의 소설에서 댓글을 수집하여 27903개 데이터를 수집했고 데이터는 데이터 번호, 소설의 제목과 장르, 댓글, 댓글 작성 날짜로 구성 돼있다.<br/>

![image](https://github.com/user-attachments/assets/ebbece09-fa20-4f51-96be-f44399d7c402)

### 1. 데이터 라벨링
* 데이터 추출 <br/>
총 27903개의 데이터중 3000개의 랜덤 데이터를 추출 하돼 원본 데이터의 소설간의 비율을 보존 한채 추출하기로 했다. <br/>
![image](https://github.com/user-attachments/assets/98b1dc0f-8d4f-4007-b373-2ed32e6e63c0)<br/>

* 긍부정 라벨링<br/>
긍정적인 내용의 댓글을 1 부정적인 댓글을 0 애매하거나 긍부정과 관련없는 댓글들을 2로 설정하여 3000개의 데이터의 라벨링을 진행했다.<br/>

|number|file_name|Comment|Date|label|
|------|---------|-------|----|-----|
|20601|전독시 퓨판|잘 보고 갑니다|20220821|1|
|19913|전독시 퓨판|잘 읽었습니다.|20240520|1|
|23278|전독시 퓨판|"즐감합니다!!건필하세요~"|20180120|1|
|20613|전독시 퓨판|잘읽었습니다. 건필하세요.|20190123|1|
|.....|..........|.................|.........|........|
|26916|회귀수선전 무림|빡웅 3회차때는 뭐였더라 마을 이장 죽이고 암살당했었나|20230426|2|
|26183|회귀수선전 무림|지인들 모두 성공했는데 고향 지구인 한명도 챙겨주지 않았네요|20230304|2|
|27427|회귀수선전 무림|진짜 잼있어요. 이런 진행이 마음에 듭니다.|20230326|1|
|27246|회귀수선전 무림|너무 억지로 둔재 조건 설정한듯|20230319|0|<br/>

### 2. 데이터 분석<br/>
데이터 분석에 앞서 모든 분석은 확실한 긍부정을 갖고 할 것이기 때문에 라벨링이 2인 애매한 항목들을 전부 제외하고 진행 할 것입니다.<br/>
* 소설별 긍부정비율과 평점간의 상관관계<br/>
평점이 높은 다는것은 독자들의 반응이 그만큼 좋았다는 것이고 부정적인 댓글들이 달리는 비율이 적다고 판단하였다. 그렇기 때문에 평점이 높은 작품과 긍부정 비율이 높은 작품의 흐름이 비슷할 것이라고 생각했다.<br/>
![image](https://github.com/user-attachments/assets/d78c4f8e-0d26-4b56-8ddc-d454dfe86636)<br/>

  * 대부분의 작품들이 평점이 높으면 댓글의 긍정적인 비율이 높아지는 정비례 관계를 가자는 것을 보아 평점과 댓글은 서로 상관관계가 높다는 것을 알 수 있다.<br/>

이를 통해 평점이 높을수록 좋은 작품이고 댓글의 여론이 좋았다는 것을 알수 있었는데 개인적으로 재밌게 읽었던 회귀수선전이 부정적인 댓글이 꽤 많았다는 것을 보고 왜 그런지 분석해보고 싶어졌다.

토픽 모델링 방법: 전체 파일에서 회귀수선전에 label 0이 붙은 부정적인 댓글들을 추출한 후 3개의 명확한 토픽으로 분류하여 왜 부정적인 댓글이 달렸는지 원인 분석을 하려고 한다<br/>
 
토픽 모델링이란? <br/>
토픽 모델링은 비정형 텍스트 데이터에서 주요 주제를 자동으로 추출하는 텍스트 마이닝 기법이다<br/>

<pre>
토픽 모델링 결과
<code>

stop_word_list = [
    '신고', '댓글', '내용', '소설', '작가', '스토리', '등장인물', '사람', '세계',
    '그리고', '하지만', '정말', '너무', '그냥', '사실', '다른', '거의', '이런', '저런', '이렇게', '그런데',
    '관계', '분위기', '부분', '상황', '역할', '관점', '문제점', '방식', '주인공', '묘사', '절정',
    '중국', '무료', '생각', '이해', '정도', '능력', '김부장', '말투', '신선', '회차',
    '자체', '기본', '본인', '작품', '이상', '이유', '새끼', '수준', '검신', '수선', '하차', '지능', '중요',
    '과장', '머리', '수도자', '범인', '둔재', '나중', '단어', '지구', '불편', '유대', '정보', '무한', '마인드',
    '현실', '시간', '유료', '천하', '기연', '인간', '버러지', '세상', '부장', '스킵', '선택', '무인', '약초',
    '소재', '정체', '직장', '언급', '납득', '직장인', '사과', '상사', '시작', '인물', '복수', '초반', '동료',
    '선전', '법칙', '치트키', '문피', '무협', '사이다', '맹주', '현경', '장르'
 
  ### 토픽 분석 결과 ###
토픽 #1: 0.121*"재능" + 0.085*"문제" + 0.083*"무공" + 0.077*"설정" + 0.069*"초식"
토픽 #2: 0.273*"회귀" + 0.049*"무림" + 0.035*"전개" + 0.032*"지도" + 0.030*"도움"
토픽 #3: 0.107*"반복" + 0.095*"경지" + 0.069*"회귀" + 0.052*"설정" + 0.039*"느낌"

### 최종 토픽 분석 결과 ###
토픽 #1: 재능, 문제, 무공, 설정, 초식
토픽 #2: 회귀, 무림, 전개, 지도, 도움
토픽 #3: 반복, 경지, 회귀, 설정, 느낌

</code>
</pre><br/><br/>

토픽 #1: 재능, 문제, 무공, 설정, 초식

무공 이름과 초식 문제이 원인이었다고 한다.

토픽 #2: 회귀, 무림, 전개, 지도, 도움

회귀 전개의 억지스러움과 관련성이 높다.

토픽 #3: 반복, 경지, 회귀, 설정, 느낌

반복적인 회귀 설정때문에 독자들이 고충을 겪었다고 한다.

* 장르별 긍부정 비율  <br/>
장르에 따라 독자들의 반응과 댓글들의 여론이 전부 다르다. 예를 들어 대체 역사물은 고증을 중요시해서 지키지 않으면 반응이 부정적이고 무협은 전통무협이 아니면 악플을 다는 등과 같이 장르별로 반응이 천차만별이다.
그래서 장르간 긍부정 비율을 살펴보려 한다.                                    
![image](https://github.com/user-attachments/assets/cc861417-348a-44e3-96ea-21c6821e9bb2)


  * 드라마 장르를 가진 작품들은 비교적 독자들이 반응이 유한것에 비해 무협을 쓰는 작가들은 다소 작품을 연재할때 고충을 겪을 것으로 보인다.
 
## 3. 모델 학습 및 검증<br/>

### 3.1 모델 학습

* 모델 학습 시 문제점<br/>
소설 댓글에는 명확한 긍부정 댓글들만 있는게 아니라 애매한 평, 소설의 내용에 관한 이야기 등등 여러가지 댓글들이 존재하는데 그 모든 항목들을 라벨 2로 설정하였다. 그 후 라벨링 결과 긍정은 1249개, 부정은 313개, 애매모호가 1438개 라벨링 2가 거의 반을 차지했다.
여기서 문제가 발생하는데 일단 첫번째 현재 모델의 목표는 긍부정 예측이기 때문에 라벨을 2개만 사용할 것인데 그러면 라벨2를 가진 모든 항들을 다 삭제해야 된다. 그렇게 되면 남는 데이터의 수는 1500개로 본래 3000개의 데이터의 반으로 줄어들어 학습후 모델의 정확도에 대한
신뢰성이 떨어진다. 두번째 현재 긍부정 비율이 1249:313으로 긍정의 비율이 압도적으로 높아 해당 모델을 학습시 나오는 정확도에 대한 신뢰도가 또 떨어진다.

* 모델 학습 방법<br/>
  해당 모델의 정확도의 신뢰도를 높이기 위해 몇가지 방법들을 사용 할 것이다.<br/>
  
  1. 학습 데이터와 검증 데이터를 나눠서 해당 모델의 과적합을 방지한다.
  2. f1를 사용하여 해당 모델의 정확도를 검증한다.
  3. 전체 데이터 셋에 대하여 모델을 사용하여 검증한다.

### 3.2 모델 학습 결과
 

  

![image](https://github.com/user-attachments/assets/36a9086d-109b-41bd-b368-4870703a8571)![image](https://github.com/user-attachments/assets/817c00df-3f92-4272-b4c2-b014c7bb8155)

위의 그래프에서 첫 번째는 학습 정확도와 검증 정확도의 변화, 두 번째는 학습 F1 점수와 검증 F1 점수의 변화를 나타냅니다. 이를 통해 모델의 성능이 에폭이 진행됨에 따라 향상되고 있음을 시각적으로 확인할 수 있습니다.

정확도 그래프<br/>
학습 정확도는 꾸준히 증가합니다.
검증 정확도는 약간의 변동이 있지만, 전반적으로 안정적입니다.<br/>

F1 점수 그래프<br/>
학습 F1 점수도 꾸준히 증가하며 모델이 학습 데이터에 대한 성능을 점진적으로 향상시킵니다.
검증 F1 점수는 비교적 안정적이나, 마지막 에폭에서 약간의 감소가 관찰됩니다. <br/>


## 4. 결론과 느낀 점 및 아쉬운 점  <br/>

30000개의 소설 댓글 데이터에서 랜덤으로 3000개의 댓글을 뽑아내어 KOELECTRA 모델을 학습 시킨 결과 학습 정확도와 검증 정확도가 둘다 88퍼센트 이상의 정확도로 시작하여 마지막 epoch까지 우샹향을 그리며 각각 93,  97퍼의 정확도를 찍으면서 학습이 잘됐다고 할 수 있다. 직접 3000개의 데이터를 
라벨링을 할 때 정도 힘들었으며 라벨링의 기준을 확실하게 세웠지만 아무래도 사람이 직접 라벨링을 하다 보니 일관성에서 문제가 생겨 학습이 잘 안 될 줄 알았지만 예상외로 결과가 잘 나와서 놀랐다. 하지만 어디까지 무료회차분의 댓글에서 랜덤으로 뽑아낸것이라 작품 전체에 대한 신뢰도냐고 하면 
애매하다고 말할 수 있기 때문에 다음부터는 차라리 한 작품에 대해 최산화나 완결까지 댓글의 여론을 분석을 해보고 싶다.




  








